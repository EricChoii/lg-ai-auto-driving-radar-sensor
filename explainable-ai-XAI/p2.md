****
### Terms
- CAM
  - GAP
- Grad-CAM
- Perturbation-based
  - LIME

# Class Activation Map (CAM)
[*Constraint of CAM*]

![image](https://user-images.githubusercontent.com/39285147/179204300-922e632a-a70e-41aa-8099-b2f5d9dc1c1a.png)
![image](https://user-images.githubusercontent.com/39285147/179204393-4dd5c474-3ee9-4796-8091-6f69c98ae99f.png)

> 수식 해석
>> GAP: 픽셀 i,j에 대한 Activation들의 총합을 Activation 크기로 나눈 것
>>
>> Yc: 클래스 c에 대한 output 분류 score

![image](https://user-images.githubusercontent.com/39285147/179205670-716e1940-0623-476b-9bf6-c93df48584c2.png)

CAM이란 Saliency map 기반 설명 가능 방법으로, CNN이 입력으로 들어온 이미지를 분류할 때 "어떤 부분을 보고" 예측을 했는지를 알려주는 역할이다.
- CAM can localize objects in image.
- Segment the regions that have the value above 20% of the max value of the CAM and take the bounding box of it

Global average pooling (GAP) 이라는 특정 레이어를 만들고, 이를 활용하여 설명을 제공한다.
- GAP should be implemented before the softmax layer (이전 Activation 연산들에 선형결합으로 softmax layer을 취한다).

> GAP Layer
>> GAP(global average pooling)은 앞에서 설명한 Max(Average) Pooling 보다 더 급격하게 feature의 수를 줄인다. GAP의 목적은 feature를 1차원 벡터로 만들기 위함이다.
>> 
>> 각 Activation map의 모든 Activation들을 평균 내는 연산이다.
>> 
>>>> 각 Activation마다 하나의 숫자를 얻게되고, 그것들이 사진 속 동그라미들로써 표현된다. 그 숫자가 클수록 인풋과 연관성이 커서 결과 사진에서 보이는 바와같이 강조되어 표시된다.

### Applications
- Object detection
- Semantic segmentation

> Weakly supervised learning 
>> 각 이미지마다 class label만 주어져 있어도 그것을 활용하여 분류기를 학습한 후에 CAM 정보를 이용해서 더 복잡한 상기 방법을 해결하는 것

## Strength / Weakness
Strength
- It **clearly shows** what objects the model is looking at

Weakness
- **Model specific**: it can be applied only to models with limited architecture(GAP이 적용된 Layer)
- It can only be obtained at the last convolutional layer and this makes the interpretation **resolution coarse**
- 객체의 boundary까지 찾아내지는 못한다.

해결법
- **Grad-CAM*

# Grad-CAM
![image](https://user-images.githubusercontent.com/39285147/179210819-8d0a9573-7079-4fba-af90-13cdfedb0648.png)
![image](https://user-images.githubusercontent.com/39285147/179213811-12a8a5bb-839e-4e55-a98b-9eeb32d87d1a.png)

CAM을 Gradient 정보를 활용해서 확장한 설명 방법으로 GAP가 없어도 적용 가능하다.
- To calculate the channel-wise weighted sum, Grad-CAM substitute weights by average pooled gradient

## Strength / Weakness
Strength
- **Model agnostic**: can be applied to various output models

Weakness
- Average gradient sometimes is not accurate
  - Gradient ↑, 해당 Activation 출력 값 민감도 ↑ (절대적으로 옳은 중요도 X)

# CAM vs. Grad-CAM
CAM은 GAP가 있어야만 사용할 수 있다. 따라서 GAP가 없는 경우 FC layer를 GAP로 대체한 후 재학습을 시켜준 후 visualzation을 진행하였다. 

반면, Grad-CAM은 '범용적으로' CAM을 사용하기 위해 CAM의 가중치 w를 해당 Activation map의 Gradient에 기반한 GAP 값으로 대체한다.

# Perturbation-based
![image](https://user-images.githubusercontent.com/39285147/179214483-7aaba83f-21a5-4693-954a-313753410034.png)

모델의 정확한 구조나 계수는 모르는 상태에서 그 모델에 대한 입출력만 가지고 있는 경우 설명하는 방법.
- 입력 데이터를 조금씩 바꾸면서 그에 대한 출력을 보고, 그 변화에 기반해서 설명한다.

## Local Interpretable Model agnostic Explanations (LIME)
![image](https://user-images.githubusercontent.com/39285147/179215251-db1a6ba2-d9f9-43d9-88e7-8256672213ad.png)

> 빨간색 포인트 주변에서는 선형 모델로 근사하여 표현하겠다는 의미.

어떤 분류기가 DL 모델처럼 매우 복잡한 비선형적 특징을 가지고 있어도 주어진 데이터 포인트에 대하여 아주 Local하게는 다 선형적인 모델로 근사화가 가능하다.
- 입력 데이터를 조금씩 바꾸면서 그에 대한 출력을 보고, 이렇게 나온 입출력 Pair(*purturbed된 이미지, 출력확률*)들을 간단한 선형 모델로 근사하여 설명한다.

### Image Example
![image](https://user-images.githubusercontent.com/39285147/179215409-90e5a86c-b308-47b5-9e4a-7e11f3b74ad1.png)

1. Use super pixels as interpretable components
2. Perturb the super pixels and obtain the local interpretation model near the given example

> Superpixel
>> Superpixel이란 유사성을 지닌 픽셀들을 일정 기준에 따라 묶어서 만든 하나의 커다란 픽셀을 말한다
